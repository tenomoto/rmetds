# CSVデータ

CSVファイルは`read.csv()`で読み込むことができます。
この函数は、data.frameと呼ばれる、リストに似たオブジェクト返します。
行や列に名前を付けて参照することができます。

## 測定データ

二酸化炭素の測定をして、1列目が日付、2列目が時刻、3列目が測定値というCSVファイルが得られたとします。

```{r}
co2 <- read.csv("co2.csv", header=FALSE)
head(co2)
```

列に名前を付けましょう。

```{r}
names(co2) <- c("date", "time", "co2")
```

名前を使って`co2$date`または`co2[["date"]]`とすると、列をベクトルとして取得できます。
`co2$["date"]`は`date`を残したdata.frameを返します。

日付と時刻を`POSIXct`に変換しておくと、時系列データを扱うときに便利です。
`POSIXct`はRの日時オブジェクトの一つで、基準時刻からの秒数で表します。
`ct`はcalendar timeを意味します。 
`POSIXlt`はlocal timeで要素を整数のベクトルで表します。

```{r}
co2$datetime <- as.POSIXct(paste(co2$date, co2$time))
head(co2)
```

## AMeDAS

過去のAMeDASデータは、気象庁 > 各種データ・資料 > [過去の気象データ・ダウンロード](https://www.data.jma.go.jp/risk/obsdl/index.php)から取得できます。 
[ファイル形式](https://www.data.jma.go.jp/risk/obsdl/top/help3.html)を参考にして読み解いていきます。
地点や変数等を選択します。
変数が多かったり、期間が長すぎたりすると、サイズの上限に達してしまいます。
その場合は、必要な変数や期間を絞ってください。 
複数の地点を選択することもできますが、ここでは1地点を選んでください。

読み込んだデータはRを使って整理することができます。
例を見てみましょう。 

列の名前は第4行目からつけることにしますので、`header=FALSE`とします。
第1～3行目はダウンロードした時刻、空行、地点名などですので、`skip=3`で無視します。
R 4.2からはUTF-8が標準になりました。
AMeDASデータのファイル形式はShift JIS（cp932）なので、`fileEncoding="cp932"`を渡します。

```{r}
raw <- read.csv("data.csv", header=FALSE, skip=3, fileEncoding="cp932")
```

raw[2,] == "品質情報"`は2行目の各要素が「品質情報」であれば`TRUE`、それ以外は`FALSE`であるベクトルです。

```{r}
raw[2,] == "品質情報"
```

これを列の論理添字としてTRUEの列について7より大きいか調べ、論理ベクトルを作ります。

```{r}
raw[,raw[2,] == "品質情報"] > 7
```

`apply()`はRの強力な函数で、1番目の引数として渡す配列の次元（MARGIN、2番目の引数）に対して、3番目に渡す函数を適用します。
ここでは`all`を渡します。 

```{r}
apply(raw[,raw[2,] == "品質情報"] > 7, 1, all)
```

品質情報が全て8（正常値）であるものを残します。
```{r}
filtered <- raw[apply(raw[,raw[2,] == "品質情報"] > 7, 1, all), ]
```

1行目の列の名前として使います。
```r
filtered <- raw[apply(raw[,raw[2,] == "品質情報"] > 7, 1, all), ]
names(filtered) <- filtered[1,]
```

Rで負の添え字は、その添え字を取り除くことを意味します。
Numpyのように後ろから数えるのではないことに注意しましょう。
1～2行目はデータではないので削除します。
以上をまとめると次のようになります。 

```r
filtered <- raw[apply(raw[,raw[2,] == "品質情報"] > 7, 1, all), ]
names(filtered) <- filtered[1,]
filtered <- filtered[c(-1,-2),]
```

## 大気微量成分 

大気の中には主要成分だけでなく、量は少ないが重要な働きをする微量成分があります。 二酸化炭素は人為起源の排出が原因で増加し続けています。 その様子をグラフにしてみましょう。 気象庁のWord Data Centre for Greenhouse Gases <https://gaw.kishou.go.jp/publications/global_mean_mole_fractions>から年平均csvデータ（Global annual mean mole fractions）のCO2ファイルをダウンロードし、作業ディレクトに保存します。

```{r}
df <- read.csv("co2_annual_20221026.csv")
plot(df$year, df$co2.global.mean.ppm.)
```

`read.csv()`はコンマ区切り（CSV, comma separated value）のデータを読む函数です。 ファイル名は文字列であることを表すために`""`で囲みます。 ファイル名の日付の部分は変わります。 グラフの種類を指定しないと、散布図になります。

`df`には読んだ表の中身が入ります。`df`はデータフレームと呼ばれるクラスのデータ構造です。データフレームは、値が行列に並んでいるだけでなく、行や列に名前がつけられます。

グラフにタイトルをつけ、軸のラベルを変更します。タイトルは`main`で、軸ラベルは`xlab`、`ylab`で指定します。

```{r}
plot(df$year, df$co2.global.mean.ppm.,
     main="Global mean CO2 concentration",
     xlab="year", ylab="CO2 ppm")
```

次に月平均データ（Global monthly mean mole fractions）を使って簡単な時系列解析をしてみます。

```{r}
dfm <- read.csv("co2_monthly_20231115.csv")
co2.mon <- dfm$mole.fraction.ppm.
n <- nrow(dfm)
co2.mon <- ts(co2.mon, start=c(dfm$year[1], dfm$month[1]), frequency=12)
co2.mon.decomp<- decompose(co2.mon)
plot(co2.mon.decomp)
```

`ts()`は一つ目の引数のデータから時系列オブジェクトを作ります。 `frequency=12`は1年を単位として12回の頻度であることを示します。 `decompose()`はデータをトレンド、周期成分と残差に分解します。

残差をさらにスペクトル分解してみましょう。

```{r}
spec.pgram(co2.mon.decomp$random, spans=c(7,7), na.action=na.omit)
abline(v=1)
abline(v=1/3)
```

`spec.pgram`は高速フーリエ変換を利用して、ピリオドグラムを計算します。 `spans`で修正ダニエル法に基づいた平滑化を施すことができます。 右上の青い線は信頼区間を表します。 `co2.mon.decomp$random`には最初と最後に数値でない値（not a number）を`na`が入っていますので、`na.action`で無視します。 ピークに近い、周期1年と3年に対応するところに縦線を入れてみました。 それぞれ年々変動とエルニーニョ現象のような数年周期に対応しているものと考えられます。

Rでは、このように対話的な簡単な操作により、簡単に解析やグラフの作成ができます。

::: {.callout-note title="練習"}
自分で計測したCO2データをグラフにしてみましょう。

`df`というテーブルがあり、`date`という名前の列に`2024/7/15`、`time`という列に`12:00:00`などのようにデータが入っているとします。これらをRの日時を表す型に変換して、列として追加するには次のようにします。
```{r}
#| eval: false
df$datetime <- as.POSIXct(paste(df$date, df$time))
```
`POSIXct`型は1970年1月1日00:00:00からの秒数です。これを横軸に取ると良いでしょう。

気象庁は様々なデータをCSV形式で提供しています。 それらをRで読んでみましょう。 うまく読めるでしょうか。

-   [「気象業務はいま2021」CSVデータ一覧](https://www.jma.go.jp/jma/kishou/books/hakusho/2021/csvindex.html)
-   [台風位置表](https://www.data.jma.go.jp/yoho/typhoon/position_table/index.html)
-   [数値データページリンク集](https://www.jma.go.jp/jma/menu/arcdata.html)
-   [最新の気象データ](https://www.data.jma.go.jp/obd/stats/data/mdrr/index.html)
:::